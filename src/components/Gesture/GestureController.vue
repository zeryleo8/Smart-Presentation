<template>
    <div class="gesture-container">
        <div class="camera-wrapper" style="transform: scaleX(-1);">
            <video ref="videoRef" autoplay playsinline id="webcam"></video>
            <canvas ref="canvasRef" id="output_canvas"></canvas>
        </div>

        <div class="status-badge active">
            <div class="indicator"></div>
            AI è§†è§‰å·²æ¿€æ´»
        </div>

        <div class="gesture-hint">
            ğŸ‘‹ æŒ¥æ‰‹ç¿»é¡µ | âœŠ æ¡æ‹³é€€å‡ºå…¨å±
        </div>
    </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onBeforeUnmount } from 'vue'
import { FilesetResolver, HandLandmarker, DrawingUtils } from '@mediapipe/tasks-vision'

// å®šä¹‰äº‹ä»¶ï¼šç¿»é¡µ å’Œ é€€å‡ºå…¨å±
const emit = defineEmits(['swipe-left', 'swipe-right', 'exit-fullscreen'])

const videoRef = ref<HTMLVideoElement | null>(null)
const canvasRef = ref<HTMLCanvasElement | null>(null)
let handLandmarker: HandLandmarker | null = null
let animationFrameId: number
let lastVideoTime = -1

// --- æŒ¥æ‰‹æ£€æµ‹å˜é‡ ---
let lastWristX: number | null = null
let lastSwipeTime = 0
const SWIPE_THRESHOLD = 0.15
const COOLDOWN = 800

// --- æ¡æ‹³æ£€æµ‹å˜é‡ ---
let fistHoldStartTime = 0
const FIST_HOLD_THRESHOLD = 600 // éœ€è¦ä¿æŒæ¡æ‹³ 600ms æ‰ä¼šè§¦å‘é€€å‡º
let isFistDetected = false

// åˆ¤æ–­æ‰‹æŒ‡å¼¯æ›² (å±å¹•åæ ‡ç³»Yå‘ä¸‹ï¼ŒæŒ‡å°–Y > å…³èŠ‚Y è¡¨ç¤ºå¼¯æ›²)
const isFingerCurled = (landmarks: any[], tipIdx: number, jointIdx: number) => {
    return landmarks[tipIdx].y > landmarks[jointIdx].y
}

// MediaPipe åˆå§‹åŒ–
const createHandLandmarker = async () => {
    try {
        const vision = await FilesetResolver.forVisionTasks("/wasm")
        handLandmarker = await HandLandmarker.createFromOptions(vision, {
            baseOptions: { modelAssetPath: "/models/hand_landmarker.task", delegate: "GPU" },
            runningMode: "VIDEO", numHands: 1
        })
        startCamera()
    } catch (e) { console.error("MediaPipe æ¨¡å‹åŠ è½½å¤±è´¥:", e) }
}

// å¼€å¯æ‘„åƒå¤´
const startCamera = async () => {
    if (!videoRef.value) return
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: { width: 320, height: 240, frameRate: { ideal: 30 } }
        })
        videoRef.value.srcObject = stream
        videoRef.value.addEventListener('loadeddata', predictWebcam)
    } catch (err) { console.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´:", err) }
}

// é€å¸§é¢„æµ‹
const predictWebcam = async () => {
    if (!handLandmarker || !videoRef.value || !canvasRef.value) return

    // è°ƒæ•´ç”»å¸ƒå°ºå¯¸åŒ¹é…è§†é¢‘æµ
    if (videoRef.value.videoWidth > 0 && canvasRef.value.width !== videoRef.value.videoWidth) {
        canvasRef.value.width = videoRef.value.videoWidth
        canvasRef.value.height = videoRef.value.videoHeight
    }

    let startTimeMs = performance.now()
    if (lastVideoTime !== videoRef.value.currentTime) {
        lastVideoTime = videoRef.value.currentTime
        const results = handLandmarker.detectForVideo(videoRef.value, startTimeMs)

        const ctx = canvasRef.value.getContext('2d')
        if (!ctx) return
        ctx.clearRect(0, 0, canvasRef.value.width, canvasRef.value.height)

        if (results.landmarks && results.landmarks.length > 0) {
            const landmarks = results.landmarks[0]

            // ç»˜åˆ¶æ‰‹éƒ¨éª¨æ¶
            const drawingUtils = new DrawingUtils(ctx)
            drawingUtils.drawConnectors(landmarks, HandLandmarker.HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 3 })
            drawingUtils.drawLandmarks(landmarks, { color: "#FF0000", lineWidth: 1 })

            // æ‰§è¡Œæ‰‹åŠ¿æ£€æµ‹é€»è¾‘
            detectGestures(landmarks)
        } else {
            // æ²¡æœ‰æ£€æµ‹åˆ°æ‰‹æ—¶ï¼Œé‡ç½®çŠ¶æ€
            lastWristX = null
            fistHoldStartTime = 0
            isFistDetected = false
        }
    }
    animationFrameId = window.requestAnimationFrame(predictWebcam)
}

const detectGestures = (landmarks: any) => {
    const now = Date.now()
    const wrist = landmarks[0]

    // =========================================
    // é€»è¾‘ 1: æŒ¥æ‰‹æ£€æµ‹ (ç¿»é¡µ) - æ¡æ‹³æ—¶ç¦ç”¨
    // =========================================
    if (!isFistDetected && now - lastSwipeTime > COOLDOWN) {
        if (lastWristX !== null) {
            const delta = wrist.x - lastWristX
            if (Math.abs(delta) > SWIPE_THRESHOLD) {
                if (delta < 0) {
                    emit('swipe-left') // Next Page
                } else {
                    emit('swipe-right') // Prev Page
                }
                lastSwipeTime = now
                lastWristX = null
            }
        }
        if (!lastWristX) lastWristX = wrist.x
        else lastWristX = lastWristX * 0.9 + wrist.x * 0.1 // ç®€å•çš„å¹³æ»‘æ»¤æ³¢
    }

    // =========================================
    // é€»è¾‘ 2: æ¡æ‹³æ£€æµ‹ (é€€å‡ºå…¨å±)
    // =========================================

    // æ£€æµ‹å››æŒ‡æ˜¯å¦å¼¯æ›² (å¿½ç•¥å¤§æ‹‡æŒ‡)
    const fingersCurled = [
        isFingerCurled(landmarks, 8, 6),   // é£ŸæŒ‡
        isFingerCurled(landmarks, 12, 10), // ä¸­æŒ‡
        isFingerCurled(landmarks, 16, 14), // æ— åæŒ‡
        isFingerCurled(landmarks, 20, 18)  // å°æŒ‡
    ]
    const curledCount = fingersCurled.filter(c => c).length

    // åˆ¤å®šä¸ºæ‹³å¤´ï¼šè‡³å°‘4æ ¹æ‰‹æŒ‡å¼¯æ›²
    if (curledCount === 4) {
        if (fistHoldStartTime === 0) {
            fistHoldStartTime = now // å¼€å§‹è®¡æ—¶
        } else if (now - fistHoldStartTime > FIST_HOLD_THRESHOLD) {
            // ä¿æŒæ‹³å¤´è¶…è¿‡è®¾å®šæ—¶é—´ï¼Œè§¦å‘é€€å‡º
            if (!isFistDetected) {
                console.log("âœŠ [è§¦å‘] æ¡æ‹³é€€å‡ºå…¨å±")
                emit('exit-fullscreen')
                isFistDetected = true // é”å®šçŠ¶æ€ï¼Œé˜²æ­¢é‡å¤è§¦å‘
            }
        }
    } else {
        // æ‰‹æŒ‡å¼ å¼€ï¼Œç«‹å³é‡ç½®è®¡æ—¶å™¨
        fistHoldStartTime = 0
        isFistDetected = false
    }
}

// ç»„ä»¶æŒ‚è½½ï¼šå¯åŠ¨
onMounted(() => {
    createHandLandmarker()
})

// ç»„ä»¶å¸è½½ï¼šæ¸…ç† (å…³é”®æ­¥éª¤)
onBeforeUnmount(() => {
    // 1. åœæ­¢åŠ¨ç”»å¸§å¾ªç¯
    cancelAnimationFrame(animationFrameId)

    // 2. å½»åº•å…³é—­æ‘„åƒå¤´ç¡¬ä»¶æµ (ç†„ç­æŒ‡ç¤ºç¯)
    if (videoRef.value && videoRef.value.srcObject) {
        const stream = videoRef.value.srcObject as MediaStream
        stream.getTracks().forEach(track => {
            track.stop()
        })
        videoRef.value.srcObject = null
    }
    handLandmarker = null
})
</script>

<style scoped>
.gesture-container {
    position: absolute;
    bottom: 20px;
    right: 20px;
    z-index: 9999;
    pointer-events: none;
    /* ç¡®ä¿ä¸é®æŒ¡PPTå†…å®¹ç‚¹å‡» */
    display: flex;
    flex-direction: column;
    align-items: flex-end;
}

.camera-wrapper {
    position: relative;
    width: 160px;
    height: 120px;
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
    background: black;
    opacity: 0.8;
}

#webcam,
#output_canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
}

.status-badge {
    margin-top: 8px;
    background: rgba(40, 167, 69, 0.8);
    color: white;
    padding: 4px 10px;
    border-radius: 4px;
    font-size: 12px;
    display: flex;
    align-items: center;
    gap: 6px;
}

.gesture-hint {
    margin-top: 4px;
    font-size: 12px;
    color: rgba(255, 255, 255, 0.8);
    text-shadow: 1px 1px 2px black;
    text-align: center;
}

.indicator {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background-color: white;
    box-shadow: 0 0 5px white;
}
</style>